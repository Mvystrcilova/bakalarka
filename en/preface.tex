\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

Millions of songs online provide an opportunity to find great songs for people with all kinds of music tastes. However, only a small fraction of all the songs that are produced becomes popular. Those are the ones people are being exposed to the most. They are promoted on various platforms such as YouTube\footnote{https://www.youtube.com} or Spotify\footnote{https://www.spotify.com}, and played across all radio stations sometimes several times a day. After a while, older songs become less popular, one could use the term \textit{"overplayed"} and other (usually new) songs take their place. But what if a person's next favorite song already existed, it just did not become popular? It is unlikely to hear unpopular but possibly likeable songs for people with unusual music preferences on the radio. Radio stations try to target as many listeners as possible. A recommender system that collects data about what a user listens to could on the other hand specifically target the person's taste and help anyone discover tracks perfectly tailored for them without being dependant on their popularity.

The suggestions recommender systems provide for basically any online content are crucial. With the amount of songs, movies, books, clothes, electronics and many more, it would be extremely time consuming for a person to go through all of the items in order to find what they are looking for. Recommendation systems are trying to make it easier for people to find what they want. They even try to predict, what they will be looking for next or what they might want but do not know it yet. 

There are three main method groups to generate (not only) music recommendations for users. First are collaborative-filtering methods (CF) where recommendations are based on the preferences of like-minded users. Second are content-based methods where recommendations are based on the song content (tags, audio, lyrics, ...) and the third group are hybrid methods combining the first two together. 

Generally, CF methods for all kinds of recommendation systems appear to be researched more extensively \cite{DBLP:journals/corr/abs-1712-07525} however, there are certain drawbacks of these approaches. Most obviously, there is a problem with new, unrated songs because no user has viewed or liked them, so they cannot be recommended to like-minded users with a method based only on collaborative filtering. This is called the cold-start problem. Also, the recommendations tend to be dependent on user popularity patterns. Nevertheless, with enough user data, collaborative filtering methods generally outperform content-based methods \cite{van2013deep}. 

Due to these observations, there are not many applications that would recommend songs based solely on their content and to the best of our knowledge, there is no music recommendation application that would recommend songs to its users based only on lyrics. As this is a logical consequence of the findings above, we believe that a recommender system based exclusively on content-based methods could be helpful for users with an unusual taste since it would not be popularity-dependant. We decided to introduce such a recommender application. 

In order to create a content-based music recommender application we need to decide on the source(s) of content information. A basic CB recommender is attribute-based. Common song attributes are the genre, the artist, creation year and so on. Nonetheless, we decided not to use these simple CB attributes in this thesis, because almost all music related application allow users to search based on tags so it would not bring anything new really. 

Instead of simple CB attributes, we chose lyrics and audio as the sources of content information. The audio channel of the song is probably the ultimate low-level content information of every song. People listen to music because it is a pleasant sound and it is likely that it is audio features that define, whether a person likes a song or not. On the other hand, processing a song's audio channel to acquire meaningful features is an expensive and complex task with many options and hyperparameters that need to be set.

Song lyrics, i.e., a textual transcript of the vocals in the song is somewhat less informative, however it may still possess valuable information, for which, multiple processing methods were already developed. The process of transforming raw lyrics into some meaningful attributes is less demanding compared to the processing of raw audio. There is an intuitive a notion that their performance might be doubtful, however, many studies evaluate them on their genre classification accuracy \cite{DBLP:journals/corr/Tsaptsinos17} or compare them to collaborative filtering systems \cite{Gossi2016LyricBasedMR} which does not always mimic actual user behaviour.

Recommendation is mostly based on similarity between items which can be defined in various ways. Both lyrics and audio need pre-processing before establishing similarity. 

\subsection*{Goals}
The goals of this thesis are:
\begin{itemize}
    \item to determine whether lyrics and audio-based methods mimic actual user behaviour and are relevant in recommender systems
    \item create a web application where these methods will be implemented to provide a recommender system which is not dependant on song popularity
\end{itemize}

In order to do so we take the following steps. We describe various ways of pre-processing text and audio signals in an unsupervised manner for content-based song similarity calculations. Then we select some of them based on previous studies and their features, evaluate their performance on real user playlists, compare the results and then implement fitting methods in a web application.

Although it originally seemed that processing both content modalities are similar, during our work on the thesis, it turned out that the complexity and diversity of the pre-processing steps exceeded our expectations. It includes language, text representation and similarity metrics for lyrics-based methods and audio extraction, audio representation
and similarity metrics for audio-based similarity. 

We decided to focus on unsupervised learning of song feature representation of both audio and text. This includes encoding a song into a vector so that a standard similarity-based recommendation technique can be used to evaluate similarity of two arbitrary songs without having any information about genre or other tags. The vectors can also be used for more advanced algorithms using for example Recurrent neural networks to calculate similarity. That is however above the scope of this work. 

The web application's main purpose is to introduce the user to new songs he has not listened to yet based on a song similarity method he selects. The songs are provided by the application's default database but adding songs is possible too and its distance to other songs is taken into account for recommendations. 
